{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94210416",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/TruongTrongDaiLong/TichChap/blob/main/flight_route_classification_tets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a4792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark session initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# PySpark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor, LinearRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import kagglehub\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"FlightRouteClassification\")\n",
    "    .master(\"local[*]\")  #  dùng tất cả CPU cores\n",
    "    .config(\"spark.driver.memory\", \"8g\")   #  tăng bộ nhớ\n",
    "    .config(\"spark.executor.memory\", \"8g\")\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# Set log level to reduce verbosity\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(\"PySpark session initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2d109e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số cột: 23\n",
      "Tên cột: ['tbl', 'Year', 'quarter', 'citymarketid_1', 'citymarketid_2', 'city1', 'city2', 'airportid_1', 'airportid_2', 'airport_1', 'airport_2', 'nsmiles', 'passengers', 'fare', 'carrier_lg', 'large_ms', 'fare_lg', 'carrier_low', 'lf_ms', 'fare_low', 'Geocoded_City1', 'Geocoded_City2', 'tbl1apk']\n",
      "Số dòng dữ liệu: 245955\n",
      "Dataset shape: (245955, 23)\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn file CSV \n",
    "csv_path = \"f:/Library/HK1_2025-2026/HocMay/Trend-Analysis-Aviation-Industry-US/data/US Airline Flight Routes and Fares 1993-2024.csv\"\n",
    "\n",
    "df = spark.read.option(\"header\", True) \\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .option(\"quote\", '\"') \\\n",
    "    .option(\"escape\", '\"') \\\n",
    "    .option(\"multiLine\", True) \\\n",
    "    .option(\"ignoreLeadingWhiteSpace\", True) \\\n",
    "    .option(\"ignoreTrailingWhiteSpace\", True) \\\n",
    "    .csv(csv_path)\n",
    "\n",
    "print(\"Số cột:\", len(df.columns))\n",
    "print(\"Tên cột:\", df.columns)\n",
    "print(\"Số dòng dữ liệu:\", df.count())\n",
    "print(f\"Dataset shape: ({df.count()}, {len(df.columns)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d90c590b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10 dòng đầu tiên :\n",
      "+-------+----+-------+--------------+--------------+------------------------------+----------------------------------+-----------+-----------+---------+---------+-------+----------+------+----------+--------+-------+-----------+------+--------+--------------+--------------+---------------------+\n",
      "|tbl    |Year|quarter|citymarketid_1|citymarketid_2|city1                         |city2                             |airportid_1|airportid_2|airport_1|airport_2|nsmiles|passengers|fare  |carrier_lg|large_ms|fare_lg|carrier_low|lf_ms |fare_low|Geocoded_City1|Geocoded_City2|tbl1apk              |\n",
      "+-------+----+-------+--------------+--------------+------------------------------+----------------------------------+-----------+-----------+---------+---------+-------+----------+------+----------+--------+-------+-----------+------+--------+--------------+--------------+---------------------+\n",
      "|Table1a|2021|3      |30135         |33195         |Allentown/Bethlehem/Easton, PA|Tampa, FL (Metropolitan Area)     |10135      |14112      |ABE      |PIE      |970    |180       |81.43 |G4        |1.0     |81.43  |G4         |1.0   |81.43   |NULL          |NULL          |202131013514112ABEPIE|\n",
      "|Table1a|2021|3      |30135         |33195         |Allentown/Bethlehem/Easton, PA|Tampa, FL (Metropolitan Area)     |10135      |15304      |ABE      |TPA      |970    |19        |208.93|DL        |0.4659  |219.98 |UA         |0.1193|154.11  |NULL          |NULL          |202131013515304ABETPA|\n",
      "|Table1a|2021|3      |30140         |30194         |Albuquerque, NM               |Dallas/Fort Worth, TX             |10140      |11259      |ABQ      |DAL      |580    |204       |184.56|WN        |0.9968  |184.44 |WN         |0.9968|184.44  |NULL          |NULL          |202131014011259ABQDAL|\n",
      "|Table1a|2021|3      |30140         |30194         |Albuquerque, NM               |Dallas/Fort Worth, TX             |10140      |11298      |ABQ      |DFW      |580    |264       |182.64|AA        |0.9774  |183.09 |AA         |0.9774|183.09  |NULL          |NULL          |202131014011298ABQDFW|\n",
      "|Table1a|2021|3      |30140         |30466         |Albuquerque, NM               |Phoenix, AZ                       |10140      |14107      |ABQ      |PHX      |328    |398       |177.11|WN        |0.6061  |184.49 |AA         |0.3939|165.77  |NULL          |NULL          |202131014014107ABQPHX|\n",
      "|Table1a|2021|3      |30140         |30721         |Albuquerque, NM               |Boston, MA (Metropolitan Area)    |10140      |10721      |ABQ      |BOS      |1974   |153       |324.97|AA        |0.4263  |323.73 |WN         |0.1609|298.2   |NULL          |NULL          |202131014010721ABQBOS|\n",
      "|Table1a|2021|3      |30140         |30721         |Albuquerque, NM               |Boston, MA (Metropolitan Area)    |10140      |13296      |ABQ      |MHT      |1974   |16        |315.9 |WN        |0.7285  |270.42 |WN         |0.7285|270.42  |NULL          |NULL          |202131014013296ABQMHT|\n",
      "|Table1a|2021|3      |30140         |30721         |Albuquerque, NM               |Boston, MA (Metropolitan Area)    |10140      |14307      |ABQ      |PVD      |1974   |22        |329.22|WN        |0.5415  |271.6  |WN         |0.5415|271.6   |NULL          |NULL          |202131014014307ABQPVD|\n",
      "|Table1a|2021|3      |30140         |30852         |Albuquerque, NM               |Washington, DC (Metropolitan Area)|10140      |10821      |ABQ      |BWI      |1670   |159       |255.89|WN        |0.7212  |244.89 |WN         |0.7212|244.89  |NULL          |NULL          |202131014010821ABQBWI|\n",
      "|Table1a|2021|3      |30140         |30852         |Albuquerque, NM               |Washington, DC (Metropolitan Area)|10140      |11278      |ABQ      |DCA      |1670   |151       |291.16|AA        |0.4404  |296.88 |WN         |0.3197|247.2   |NULL          |NULL          |202131014011278ABQDCA|\n",
      "+-------+----+-------+--------------+--------------+------------------------------+----------------------------------+-----------+-----------+---------+---------+-------+----------+------+----------+--------+-------+-----------+------+--------+--------------+--------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 10 dòng đầu tiên :\")\n",
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f46e6605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "['tbl', 'Year', 'quarter', 'citymarketid_1', 'citymarketid_2', 'city1', 'city2', 'airportid_1', 'airportid_2', 'airport_1', 'airport_2', 'nsmiles', 'passengers', 'fare', 'carrier_lg', 'large_ms', 'fare_lg', 'carrier_low', 'lf_ms', 'fare_low', 'Geocoded_City1', 'Geocoded_City2', 'tbl1apk']\n",
      "\n",
      "Data types:\n",
      "tbl: StringType()\n",
      "Year: IntegerType()\n",
      "quarter: IntegerType()\n",
      "citymarketid_1: IntegerType()\n",
      "citymarketid_2: IntegerType()\n",
      "city1: StringType()\n",
      "city2: StringType()\n",
      "airportid_1: IntegerType()\n",
      "airportid_2: IntegerType()\n",
      "airport_1: StringType()\n",
      "airport_2: StringType()\n",
      "nsmiles: IntegerType()\n",
      "passengers: IntegerType()\n",
      "fare: DoubleType()\n",
      "carrier_lg: StringType()\n",
      "large_ms: DoubleType()\n",
      "fare_lg: DoubleType()\n",
      "carrier_low: StringType()\n",
      "lf_ms: DoubleType()\n",
      "fare_low: DoubleType()\n",
      "Geocoded_City1: StringType()\n",
      "Geocoded_City2: StringType()\n",
      "tbl1apk: StringType()\n"
     ]
    }
   ],
   "source": [
    "# Display column names and data types\n",
    "print(\"Column names:\")\n",
    "print(df.columns)\n",
    "print(\"\\nData types:\")\n",
    "for field in df.schema.fields:\n",
    "    print(f\"{field.name}: {field.dataType}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43cda9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giá trị thiếu theo cột:\n",
      "+--------------+-------------+------------------+\n",
      "|Column        |Missing_Count|Percent           |\n",
      "+--------------+-------------+------------------+\n",
      "|Geocoded_City2|39206        |15.940314285133459|\n",
      "|Geocoded_City1|39206        |15.940314285133459|\n",
      "|fare_low      |1612         |0.6554044439023399|\n",
      "|lf_ms         |1612         |0.6554044439023399|\n",
      "|carrier_low   |1612         |0.6554044439023399|\n",
      "|large_ms      |1540         |0.626130796283873 |\n",
      "|fare_lg       |1540         |0.626130796283873 |\n",
      "|carrier_lg    |1540         |0.626130796283873 |\n",
      "+--------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================== 1. DATA CLEANING ====================\n",
    "# Kiểm tra missing values\n",
    "print(\"Giá trị thiếu theo cột:\")\n",
    "from pyspark.sql.functions import col as spark_col, when, sum as spark_sum, lit\n",
    "\n",
    "# Tổng số dòng\n",
    "_total = df.count()\n",
    "\n",
    "# Tính số lượng thiếu cho từng cột bằng một lần quét\n",
    "missing_row = df.select([\n",
    "    spark_sum(when(spark_col(c).isNull(), 1).otherwise(0)).alias(c) for c in df.columns\n",
    "]).collect()[0]\n",
    "\n",
    "# Tạo DataFrame hiển thị Missing_Count và Percent\n",
    "missing_records = []\n",
    "for c in df.columns:\n",
    "    miss = int(missing_row[c]) if missing_row[c] is not None else 0\n",
    "    if miss > 0:\n",
    "        pct = (miss / _total * 100) if _total > 0 else 0\n",
    "        missing_records.append((c, miss, float(pct)))\n",
    "\n",
    "missing_df = spark.createDataFrame(missing_records, [\"Column\", \"Missing_Count\", \"Percent\"]) \\\n",
    "    .orderBy(spark_col(\"Missing_Count\").desc())\n",
    "\n",
    "if missing_df.count() > 0:\n",
    "    missing_df.show(truncate=False)\n",
    "else:\n",
    "    print(\"Không có giá trị thiếu nào trong DataFrame!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f929fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số dòng trước khi loại null: 245955\n",
      "Số dòng sau khi loại null: 244343\n",
      "\n",
      "Số dòng trùng lặp đã loại bỏ: 0\n",
      "\n",
      "Kiểm tra tính hợp lệ...\n",
      "  - large_ms không hợp lệ: 0\n",
      "  - lf_ms không hợp lệ: 0\n",
      "\n",
      " Dữ liệu sau khi làm sạch: (237985, 23)\n",
      "\n",
      "Hoàn tất làm sạch dữ liệu.\n"
     ]
    }
   ],
   "source": [
    "# Loại bỏ các hàng có giá trị null trong các cột quan trọng\n",
    "cols_to_check = [\n",
    "    \"lf_ms\", \"carrier_low\", \"fare_low\",\n",
    "    \"large_ms\", \"fare_lg\", \"carrier_lg\"\n",
    "]\n",
    "\n",
    "# Loại bỏ các hàng có giá trị null trong các cột này\n",
    "df_clean = df.dropna(subset=cols_to_check)\n",
    "\n",
    "print(\"Số dòng trước khi loại null:\", df.count())\n",
    "print(\"Số dòng sau khi loại null:\", df_clean.count())\n",
    "\n",
    "# 4️ Loại bỏ trùng lặp\n",
    "initial_count = df_clean.count()\n",
    "df_clean = df_clean.dropDuplicates()\n",
    "removed = initial_count - df_clean.count()\n",
    "print(f\"\\nSố dòng trùng lặp đã loại bỏ: {removed}\")\n",
    "\n",
    "# 5 Kiểm tra và lọc dữ liệu không hợp lệ\n",
    "print(\"\\nKiểm tra tính hợp lệ...\")\n",
    "\n",
    "# Market share trong [0,100]\n",
    "for c in ['large_ms', 'lf_ms']:\n",
    "    if c in df_clean.columns:\n",
    "        invalid = df_clean.filter((col(c) < 0) | (col(c) > 100)).count()\n",
    "        print(f\"  - {c} không hợp lệ: {invalid}\")\n",
    "        df_clean = df_clean.filter((col(c) >= 0) & (col(c) <= 100))\n",
    "\n",
    "# passengers & fare > 0\n",
    "for c in ['passengers', 'fare']:\n",
    "    if c in df_clean.columns:\n",
    "        df_clean = df_clean.filter(col(c) > 0)\n",
    "\n",
    "# 7️ Kết quả\n",
    "df_clean = df_clean\n",
    "\n",
    "rows_final = df_clean.count()\n",
    "cols_final = len(df_clean.columns)\n",
    "print(f\"\\n Dữ liệu sau khi làm sạch: ({rows_final}, {cols_final})\")\n",
    "\n",
    "print(\"\\nHoàn tất làm sạch dữ liệu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "352c8cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BƯỚC 2: PHÂN TÍCH KHÁM PHÁ DỮ LIỆU (EDA)\n",
      "================================================================================\n",
      "\n",
      "Thống kê mô tả các biến số:\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Column                    Count       Mean        Std        Min         Q1     Median         Q3        Max\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Year                     237985    2008.64       8.66       1993       2001       2009       2016       2024\n",
      "quarter                  237985       2.48       1.12          1          1          2          3          4\n",
      "citymarketid_1           237985   31556.83    1094.45      30135      30721      31295      32467      35412\n",
      "citymarketid_2           237985   32175.24    1232.17      30189      30977      32211      33192      35628\n",
      "airportid_1              237985   12438.23    1430.69      10135      11193      12266      13487      16440\n",
      "airportid_2              237985   13239.73    1425.33      10466      12197      13303      14679      15919\n",
      "nsmiles                  237985    1189.61     699.24        109        632       1021       1733       2724\n",
      "passengers               237985     309.50     516.89          1         26        122        353       8301\n",
      "fare                     237985     216.88      74.31      50.41      164.9     208.92     261.33    1161.22\n",
      "large_ms                 237985       0.66       0.22        0.1       0.48       0.65       0.86        1.0\n",
      "fare_lg                  237985     217.17      79.29      50.41     161.79     207.72     262.34    1501.42\n",
      "lf_ms                    237985       0.44       0.33       0.01       0.15     0.3474     0.7273        1.0\n",
      "fare_low                 237985     188.66      67.29       50.1     140.06      181.1     228.49    1269.78\n"
     ]
    }
   ],
   "source": [
    "# ==================== 2. EXPLORATORY DATA ANALYSIS ====================\n",
    "from pyspark.sql.types import IntegerType, LongType, FloatType, DoubleType\n",
    "from pyspark.sql.functions import col, count, mean, stddev, min, max, percentile_approx\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BƯỚC 2: PHÂN TÍCH KHÁM PHÁ DỮ LIỆU (EDA)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Lấy các cột số\n",
    "numeric_cols = [field.name for field in df_clean.schema.fields if field.dataType in [IntegerType(), LongType(), FloatType(), DoubleType()]]\n",
    "\n",
    "# Header đẹp\n",
    "header = f\"{'Column':<20} {'Count':>10} {'Mean':>10} {'Std':>10} {'Min':>10} {'Q1':>10} {'Median':>10} {'Q3':>10} {'Max':>10}\"\n",
    "print(\"\\nThống kê mô tả các biến số:\")\n",
    "print(\"-\" * len(header))\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "# Thống kê từng cột\n",
    "for col_name in numeric_cols:\n",
    "    if col_name in df_clean.columns:\n",
    "        stats = df_clean.select(\n",
    "            count(col(col_name)).alias(\"count\"),\n",
    "            mean(col(col_name)).alias(\"mean\"),\n",
    "            stddev(col(col_name)).alias(\"std\"),\n",
    "            min(col(col_name)).alias(\"min\"),\n",
    "            max(col(col_name)).alias(\"max\"),\n",
    "            percentile_approx(col(col_name), 0.25).alias(\"q1\"),\n",
    "            percentile_approx(col(col_name), 0.5).alias(\"median\"),\n",
    "            percentile_approx(col(col_name), 0.75).alias(\"q3\")\n",
    "        ).collect()[0]\n",
    "\n",
    "        print(f\"{col_name:<20} \"\n",
    "              f\"{stats['count']:>10} \"\n",
    "              f\"{stats['mean']:>10.2f} \"\n",
    "              f\"{stats['std']:>10.2f} \"\n",
    "              f\"{stats['min']:>10} \"\n",
    "              f\"{stats['q1']:>10} \"\n",
    "              f\"{stats['median']:>10} \"\n",
    "              f\"{stats['q3']:>10} \"\n",
    "              f\"{stats['max']:>10}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5781e1",
   "metadata": {},
   "source": [
    "#  PHÂN LOẠI TUYẾN BAY THEO TIỀM NĂNG PHÁT TRIỂN\n",
    "\n",
    "## Mục tiêu:\n",
    "- Phân loại các tuyến bay thành 3 nhóm: **Cao**, **Trung bình**, **Thấp** tiềm năng\n",
    "- Sử dụng Machine Learning để dự đoán tiềm năng phát triển\n",
    "- Đưa ra khuyến nghị chiến lược cho từng nhóm tuyến bay\n",
    "\n",
    "## Tiêu chí đánh giá tiềm năng:\n",
    "1. **Lưu lượng hành khách** (passengers)\n",
    "2. **Giá vé trung bình** (fare) \n",
    "3. **Khoảng cách** (nsmiles)\n",
    "4. **Thị phần hãng lớn** (large_ms)\n",
    "5. **Thị phần hãng giá rẻ** (lf_ms)\n",
    "6. **Xu hướng tăng trưởng** (dựa trên dữ liệu theo thời gian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130ce71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BƯỚC 1: TÍNH TOÁN ĐIỂM SỐ TIỀM NĂNG\n",
      "==================================================\n",
      "\n",
      "Phân bố tiềm năng tuyến bay:\n",
      "+---------------+------+\n",
      "|potential_level| count|\n",
      "+---------------+------+\n",
      "|            Cao| 27047|\n",
      "|           Thấp|120694|\n",
      "|     Trung bình| 90244|\n",
      "+---------------+------+\n",
      "\n",
      "\n",
      "Tỷ lệ phần trăm:\n",
      "+---------------+------+----------+\n",
      "|potential_level| count|percentage|\n",
      "+---------------+------+----------+\n",
      "|            Cao| 27047|    11.365|\n",
      "|           Thấp|120694|    50.715|\n",
      "|     Trung bình| 90244|     37.92|\n",
      "+---------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BƯỚC 1: TÍNH TOÁN ĐIỂM SỐ TIỀM NĂNG (POTENTIAL SCORE)\n",
    "\n",
    "print(\"BƯỚC 1: TÍNH TOÁN ĐIỂM SỐ TIỀM NĂNG\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Tạo bản sao dữ liệu để xử lý\n",
    "df_potential = df_clean\n",
    "\n",
    "# 1. Chuẩn hóa các chỉ số (0-1 scale)\n",
    "\n",
    "# Các chỉ số cần chuẩn hóa\n",
    "metrics = ['passengers', 'fare', 'nsmiles', 'large_ms', 'lf_ms']\n",
    "\n",
    "# Calculate min and max for normalization\n",
    "min_max_stats = {}\n",
    "for metric in metrics:\n",
    "    if metric in df_potential.columns:\n",
    "        stats = df_potential.select(\n",
    "            min(col(metric)).alias(\"min_val\"),\n",
    "            max(col(metric)).alias(\"max_val\")\n",
    "        ).collect()[0]\n",
    "        min_max_stats[metric] = {\n",
    "            'min': stats['min_val'],\n",
    "            'max': stats['max_val']\n",
    "        }\n",
    "\n",
    "# Normalize each metric\n",
    "for metric in metrics:\n",
    "    if metric in df_potential.columns and metric in min_max_stats:\n",
    "        min_val = min_max_stats[metric]['min']\n",
    "        max_val = min_max_stats[metric]['max']\n",
    "        if max_val != min_val:\n",
    "            df_potential = df_potential.withColumn(\n",
    "                f'{metric}_normalized',\n",
    "                (col(metric) - min_val) / (max_val - min_val)\n",
    "            )\n",
    "        else:\n",
    "            df_potential = df_potential.withColumn(f'{metric}_normalized', lit(0.0))\n",
    "\n",
    "# 2. Tính điểm số tiềm năng dựa trên trọng số\n",
    "# Trọng số: passengers (30%), fare (20%), nsmiles (%), large_ms (15%), lf_ms (15%)\n",
    "\n",
    "weights = { \n",
    "    'passengers_normalized': 0.25, # Lưu lượng hành khách - quan trọng nhất \n",
    "    'fare_normalized': 0.2, # Giá vé - chỉ số lợi nhuận \n",
    "    'nsmiles_normalized': 0.25, # Khoảng cách - ảnh hưởng đến chi phí \n",
    "    'large_ms_normalized': 0.15, # Thị phần hãng lớn - ổn định \n",
    "    'lf_ms_normalized': 0.15 # Thị phần hãng giá rẻ - cạnh tranh \n",
    "    }\n",
    "\n",
    "# Calculate potential score\n",
    "potential_score_expr = lit(0.0)\n",
    "for metric, weight in weights.items():\n",
    "    if metric in df_potential.columns:\n",
    "        potential_score_expr = potential_score_expr + (col(metric) * weight)\n",
    "\n",
    "df_potential = df_potential.withColumn('potential_score', potential_score_expr)\n",
    "\n",
    "# 3. Phân loại theo điểm số tiềm năng\n",
    "# Cao: >= 0.4, Trung bình: 0.3-0.4, Thấp: < 0.3\n",
    "df_potential = df_potential.withColumn(\n",
    "    'potential_level',\n",
    "    when(col('potential_score') > 0.4, 'Cao')\n",
    "    .when(col('potential_score') >= 0.3, 'Trung bình')\n",
    "    .otherwise('Thấp')\n",
    ")\n",
    "\n",
    "# 4. Thống kê phân bố\n",
    "print(\"\\nPhân bố tiềm năng tuyến bay:\")\n",
    "potential_dist = df_potential.groupBy('potential_level').count().orderBy('potential_level')\n",
    "potential_dist.show()\n",
    "\n",
    "# Calculate percentages\n",
    "total_count = df_potential.count()\n",
    "potential_percentages = df_potential.groupBy('potential_level').count() \\\n",
    "    .withColumn('percentage', round(col('count') / total_count * 100, 3))\\\n",
    "    .orderBy('potential_level')\n",
    "print(\"\\nTỷ lệ phần trăm:\")\n",
    "potential_percentages.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90f4c8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thống kê mô tả theo nhóm tiềm năng:\n",
      "+---------------+--------------+--------+-----------+------------+---------+\n",
      "|potential_level|avg_passengers|avg_fare|avg_nsmiles|avg_large_ms|avg_lf_ms|\n",
      "+---------------+--------------+--------+-----------+------------+---------+\n",
      "|            Cao|       290.126| 266.536|   1906.513|       0.816|    0.743|\n",
      "|           Thấp|       329.452| 199.544|     905.14|        0.59|    0.273|\n",
      "|     Trung bình|       288.611| 225.185|   1355.191|       0.707|    0.571|\n",
      "+---------------+--------------+--------+-----------+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Thống kê mô tả theo từng nhóm tiềm năng\n",
    "print(\"\\nThống kê mô tả theo nhóm tiềm năng:\")\n",
    "potential_stats = df_potential.groupBy('potential_level') \\\n",
    "    .agg(\n",
    "        round(mean('passengers'), 3).alias('avg_passengers'),\n",
    "        round(mean('fare'), 3).alias('avg_fare'),\n",
    "        round(mean('nsmiles'), 3).alias('avg_nsmiles'),\n",
    "        round(mean('large_ms'), 3).alias('avg_large_ms'),\n",
    "        round(mean('lf_ms'), 3).alias('avg_lf_ms')\n",
    "    ).orderBy('potential_level')\n",
    "potential_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d3b1d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BƯỚC 2: PHÂN TÍCH XU HƯỚNG TĂNG TRƯỞNG\n",
      "==================================================\n",
      "Phân bố tiềm năng sau khi cải tiến:\n",
      "+------------------------+------+\n",
      "|potential_level_enhanced| count|\n",
      "+------------------------+------+\n",
      "|                     Cao| 12036|\n",
      "|                    Thấp|152854|\n",
      "|              Trung bình| 73095|\n",
      "+------------------------+------+\n",
      "\n",
      "\n",
      "Tỷ lệ phần trăm:\n",
      "+------------------------+------+------------------+\n",
      "|potential_level_enhanced| count|        percentage|\n",
      "+------------------------+------+------------------+\n",
      "|                     Cao| 12036| 5.057461604722987|\n",
      "|                    Thấp|152854| 64.22841775742168|\n",
      "|              Trung bình| 73095|30.714120637855324|\n",
      "+------------------------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BƯỚC 2: PHÂN TÍCH XU HƯỚNG TĂNG TRƯỞNG\n",
    "\n",
    "print(\"\\nBƯỚC 2: PHÂN TÍCH XU HƯỚNG TĂNG TRƯỞNG\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate growth trends for each route using window functions\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Create window partitioned by route (city1, city2) and ordered by Year\n",
    "window_spec = Window.partitionBy('city1', 'city2').orderBy('Year')\n",
    "\n",
    "# Calculate first and last values for each route\n",
    "df_with_growth = df_potential.withColumn(\n",
    "    'first_passengers',\n",
    "    first('passengers').over(window_spec)\n",
    ").withColumn(\n",
    "    'last_passengers', \n",
    "    last('passengers').over(window_spec)\n",
    ").withColumn(\n",
    "    'first_fare',\n",
    "    first('fare').over(window_spec)\n",
    ").withColumn(\n",
    "    'last_fare',\n",
    "    last('fare').over(window_spec)\n",
    ")\n",
    "\n",
    "# Calculate growth rates\n",
    "df_with_growth = df_with_growth.withColumn(\n",
    "    'passenger_growth',\n",
    "    when(col('first_passengers') > 0, \n",
    "         (col('last_passengers') - col('first_passengers')) / col('first_passengers'))\n",
    "    .otherwise(0)\n",
    ").withColumn(\n",
    "    'fare_growth',\n",
    "    when(col('first_fare') > 0,\n",
    "         (col('last_fare') - col('first_fare')) / col('first_fare'))\n",
    "    .otherwise(0)\n",
    ")\n",
    "\n",
    "# Calculate combined growth score (passengers weighted 70%, fare 30%)\n",
    "df_with_growth = df_with_growth.withColumn(\n",
    "    'growth_trend',\n",
    "    0.7 * col('passenger_growth') + 0.3 * col('fare_growth')\n",
    ")\n",
    "\n",
    "# Normalize growth trend\n",
    "growth_stats = df_with_growth.select(\n",
    "    min('growth_trend').alias('min_growth'),\n",
    "    max('growth_trend').alias('max_growth')\n",
    ").collect()[0]\n",
    "\n",
    "min_growth = growth_stats['min_growth']\n",
    "max_growth = growth_stats['max_growth']\n",
    "\n",
    "if max_growth != min_growth:\n",
    "    df_with_growth = df_with_growth.withColumn(\n",
    "        'growth_trend_normalized',\n",
    "        (col('growth_trend') - min_growth) / (max_growth - min_growth)\n",
    "    )\n",
    "else:\n",
    "    df_with_growth = df_with_growth.withColumn('growth_trend_normalized', lit(0.0))\n",
    "\n",
    "# Update potential score with growth trend (10% weight)\n",
    "df_potential = df_with_growth.withColumn(\n",
    "    'potential_score_enhanced',\n",
    "    col('potential_score') * 0.9 + col('growth_trend_normalized') * 0.1\n",
    ")\n",
    "\n",
    "# Reclassify with enhanced score    \n",
    "df_potential = df_potential.withColumn(\n",
    "    'potential_level_enhanced',\n",
    "    when(col('potential_score_enhanced') > 0.4, 'Cao')\n",
    "    .when(col('potential_score_enhanced') >= 0.3, 'Trung bình')\n",
    "    .otherwise('Thấp')\n",
    ")\n",
    "\n",
    "print(\"Phân bố tiềm năng sau khi cải tiến:\")\n",
    "enhanced_dist = df_potential.groupBy('potential_level_enhanced').count().orderBy('potential_level_enhanced')\n",
    "enhanced_dist.show()\n",
    "\n",
    "# Calculate percentages\n",
    "enhanced_percentages = df_potential.groupBy('potential_level_enhanced').count() \\\n",
    "    .withColumn('percentage', col('count') / df_potential.count() * 100) \\\n",
    "    .orderBy('potential_level_enhanced')\n",
    "print(\"\\nTỷ lệ phần trăm:\")\n",
    "enhanced_percentages.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c95580d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các cột hiện có trong df_potential:\n",
      "['tbl', 'Year', 'quarter', 'citymarketid_1', 'citymarketid_2', 'city1', 'city2', 'airportid_1', 'airportid_2', 'airport_1', 'airport_2', 'nsmiles', 'passengers', 'fare', 'carrier_lg', 'large_ms', 'fare_lg', 'carrier_low', 'lf_ms', 'fare_low', 'Geocoded_City1', 'Geocoded_City2', 'tbl1apk', 'passengers_normalized', 'fare_normalized', 'nsmiles_normalized', 'large_ms_normalized', 'lf_ms_normalized', 'potential_score', 'potential_level', 'first_passengers', 'last_passengers', 'first_fare', 'last_fare', 'passenger_growth', 'fare_growth', 'growth_trend', 'growth_trend_normalized', 'potential_score_enhanced', 'potential_level_enhanced']\n"
     ]
    }
   ],
   "source": [
    "print(\"Các cột hiện có trong df_potential:\")\n",
    "print(df_potential.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa4e904d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BƯỚC 3: HUẤN LUYỆN MÔ HÌNH MACHINE LEARNING\n",
      "==================================================\n",
      "Kích thước dữ liệu:\n",
      "  - Train: 190573 mẫu\n",
      "  - Test: 47412 mẫu\n",
      "  - Số đặc trưng: 8\n"
     ]
    }
   ],
   "source": [
    "# BƯỚC 3: HUẤN LUYỆN MÔ HÌNH MACHINE LEARNING\n",
    "\n",
    "print(\"\\nBƯỚC 3: HUẤN LUYỆN MÔ HÌNH MACHINE LEARNING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Chuẩn bị các đặc trưng \n",
    "features_ml = ['passengers', 'fare', 'nsmiles', 'large_ms', 'lf_ms', 'fare_lg', 'fare_low', 'growth_trend']\n",
    "\n",
    "# Tạo feature vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=features_ml,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# String indexer for target variable\n",
    "label_indexer = StringIndexer(\n",
    "    inputCol=\"potential_level_enhanced\",\n",
    "    outputCol=\"label\"\n",
    ")\n",
    "# Create pipeline for feature preparation\n",
    "feature_pipeline = Pipeline(stages=[assembler, label_indexer])\n",
    "df_ml = feature_pipeline.fit(df_potential).transform(df_potential)\n",
    "\n",
    "# Split data\n",
    "train_data, test_data = df_ml.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Kích thước dữ liệu:\")\n",
    "print(f\"  - Train: {train_data.count()} mẫu\")\n",
    "print(f\"  - Test: {test_data.count()} mẫu\")\n",
    "print(f\"  - Số đặc trưng: {len(features_ml)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6e9bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm đánh giá mô hình\n",
    "def evaluate_model(predictions):\n",
    "    evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    evaluator_pre = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "    evaluator_rec = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "    accuracy = evaluator_acc.evaluate(predictions)\n",
    "    precision = evaluator_pre.evaluate(predictions)\n",
    "    recall = evaluator_rec.evaluate(predictions)\n",
    "    f1 = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "    print(f\"  - Accuracy : {accuracy:.4f}\")\n",
    "    print(f\"  - Precision: {precision:.4f}\")\n",
    "    print(f\"  - Recall   : {recall:.4f}\")\n",
    "    print(f\"  - F1-Score : {f1:.4f}\")\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a5f58ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HUẤN LUYỆN MÔ HÌNH: Random Forest\n",
      "------------------------------------------------------------\n",
      "Kết quả đánh giá Random Forest:\n",
      "  - Accuracy : 0.8986\n",
      "  - Precision: 0.9009\n",
      "  - Recall   : 0.8986\n",
      "  - F1-Score : 0.8990\n"
     ]
    }
   ],
   "source": [
    "# 1️ RANDOM FOREST\n",
    "\n",
    "print(\"\\n HUẤN LUYỆN MÔ HÌNH: Random Forest\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"label\", \n",
    "    numTrees=20,\n",
    "    maxDepth=5,\n",
    "    seed=42)\n",
    "rf_model = rf.fit(train_data)\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "\n",
    "print(\"Kết quả đánh giá Random Forest:\")\n",
    "rf_accuracy = evaluate_model(rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d558a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HUẤN LUYỆN MÔ HÌNH: Logistic Regression\n",
      "------------------------------------------------------------\n",
      "Kết quả đánh giá Logistic Regression:\n",
      "  - Accuracy : 0.9421\n",
      "  - Precision: 0.9451\n",
      "  - Recall   : 0.9421\n",
      "  - F1-Score : 0.9365\n"
     ]
    }
   ],
   "source": [
    "# 2 LOGISTIC REGRESSION\n",
    "\n",
    "print(\"\\n HUẤN LUYỆN MÔ HÌNH: Logistic Regression\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Chỉ có L2 regularization\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"label\", \n",
    "    maxIter=100, \n",
    "    regParam=0.01)\n",
    "lr_model = lr.fit(train_data)\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "\n",
    "print(\"Kết quả đánh giá Logistic Regression:\")\n",
    "lr_accuracy = evaluate_model(lr_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8566a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " So sánh mô hình:\n",
      "   Random Forest: Accuracy = 0.8986\n",
      "* Logistic Regression: Accuracy = 0.9421\n",
      "\n",
      " Mô hình tốt nhất: Logistic Regression (Độ chính xác = 0.9421)\n"
     ]
    }
   ],
   "source": [
    "# SO SÁNH HIỆU SUẤT CÁC MÔ HÌNH\n",
    "import builtins  # dùng hàm max gốc của Python\n",
    "\n",
    "models = [\"Random Forest\", \"Logistic Regression\"]\n",
    "accuracies = [rf_accuracy, lr_accuracy]\n",
    "\n",
    "best_model_index = accuracies.index(builtins.max(accuracies))\n",
    "best_model_name = models[best_model_index]\n",
    "best_accuracy = accuracies[best_model_index]\n",
    "\n",
    "print(\"\\n So sánh mô hình:\")\n",
    "for name, acc in zip(models, accuracies):\n",
    "    marker = \"*\" if name == best_model_name else \"  \"\n",
    "    print(f\"{marker} {name}: Accuracy = {acc:.4f}\")\n",
    "\n",
    "print(f\"\\n Mô hình tốt nhất: {best_model_name} (Độ chính xác = {best_accuracy:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e54face",
   "metadata": {},
   "source": [
    "## Tìm siêu tham số tối ưu cho từng mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83296912",
   "metadata": {},
   "source": [
    "###  `Random Forest` – Tìm siêu tham số tối ưu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03eb3ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Random Forest parameters:\n",
      "  numTrees = 100\n",
      "  maxDepth = 15\n",
      "  maxBins  = 64\n",
      " Accuracy (Random Forest): 0.9795\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", seed=42)\n",
    "\n",
    "paramGrid_rf = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(rf.numTrees, [20, 35, 50, 75, 100])\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15])\n",
    "    .addGrid(rf.maxBins, [32, 64])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "cv_rf = CrossValidator(\n",
    "    estimator=rf,\n",
    "    estimatorParamMaps=paramGrid_rf,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    parallelism=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "cvModel_rf = cv_rf.fit(train_data)\n",
    "best_rf_model = cvModel_rf.bestModel\n",
    "rf_predictions = best_rf_model.transform(test_data)\n",
    "\n",
    "print(\" Best Random Forest parameters:\")\n",
    "print(f\"  numTrees = {best_rf_model.getNumTrees}\")\n",
    "print(f\"  maxDepth = {best_rf_model.getOrDefault('maxDepth')}\")\n",
    "print(f\"  maxBins  = {best_rf_model.getOrDefault('maxBins')}\")\n",
    "\n",
    "rf_accuracy = evaluator.evaluate(rf_predictions)\n",
    "print(f\" Accuracy (Random Forest): {rf_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8bb115",
   "metadata": {},
   "source": [
    "### `Logistic Regression` – Tối ưu hoá regParam, elasticNetParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc476190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Logistic Regression parameters:\n",
      "  regParam = 0.001\n",
      "  elasticNetParam = 1.0\n",
      " Accuracy (Logistic Regression): 0.9950\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=1000)\n",
    "\n",
    "paramGrid_lr = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(lr.regParam, [0.001, 0.01, 0.1, 0.3, 0.5, 1.0])\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0])  # 0=L2, 1=L1\n",
    "    .build()\n",
    ")\n",
    "\n",
    "cv_lr = CrossValidator(\n",
    "    estimator=lr,\n",
    "    estimatorParamMaps=paramGrid_lr,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    parallelism=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "cvModel_lr = cv_lr.fit(train_data)\n",
    "best_lr_model = cvModel_lr.bestModel\n",
    "lr_predictions = best_lr_model.transform(test_data)\n",
    "\n",
    "print(\" Best Logistic Regression parameters:\")\n",
    "print(f\"  regParam = {best_lr_model.getRegParam()}\")\n",
    "print(f\"  elasticNetParam = {best_lr_model.getElasticNetParam()}\")\n",
    "\n",
    "lr_accuracy = evaluator.evaluate(lr_predictions)\n",
    "print(f\" Accuracy (Logistic Regression): {lr_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3932a49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " So sánh mô hình:\n",
      "   Random Forest: Accuracy = 0.9795\n",
      "     numTrees: 100\n",
      "     maxDepth: 15\n",
      "     maxBins: 64\n",
      "--------------------------------------------------\n",
      " Logistic Regression: Accuracy = 0.9950\n",
      "     regParam: 0.001\n",
      "     elasticNetParam: 1.0\n",
      "--------------------------------------------------\n",
      "\n",
      " Mô hình tốt nhất: Logistic Regression (Độ chính xác = 0.9950)\n",
      "  Siêu tham số tối ưu:\n",
      "   regParam: 0.001\n",
      "   elasticNetParam: 1.0\n"
     ]
    }
   ],
   "source": [
    "import builtins  # dùng max gốc của Python\n",
    "\n",
    "models_info = [\n",
    "    {\n",
    "        \"name\": \"Random Forest\",\n",
    "        \"accuracy\": rf_accuracy,\n",
    "        \"params\": {\n",
    "            \"numTrees\": best_rf_model.getNumTrees,\n",
    "            \"maxDepth\": best_rf_model.getOrDefault(\"maxDepth\"),\n",
    "            \"maxBins\": best_rf_model.getOrDefault(\"maxBins\")\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Logistic Regression\",\n",
    "        \"accuracy\": lr_accuracy,\n",
    "        \"params\": {\n",
    "            \"regParam\": best_lr_model.getRegParam(),\n",
    "            \"elasticNetParam\": best_lr_model.getElasticNetParam()\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Dùng builtins.max \n",
    "best_model = builtins.max(models_info, key=lambda m: m[\"accuracy\"])\n",
    "\n",
    "print(\"\\n So sánh mô hình:\")\n",
    "for m in models_info:\n",
    "    marker = \"\" if m[\"name\"] == best_model[\"name\"] else \"  \"\n",
    "    print(f\"{marker} {m['name']}: Accuracy = {m['accuracy']:.4f}\")\n",
    "    for k, v in m[\"params\"].items():\n",
    "        print(f\"     {k}: {v}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(f\"\\n Mô hình tốt nhất: {best_model['name']} (Độ chính xác = {best_model['accuracy']:.4f})\")\n",
    "print(\"  Siêu tham số tối ưu:\")\n",
    "for k, v in best_model[\"params\"].items():\n",
    "    print(f\"   {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38653a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dự đoán 10 mẫu ngẫu nhiên bằng mô hình tốt nhất: Logistic Regression\n",
      "+-------------------------------------+-------------------------------------+----------+------+-------+--------+------+-------+--------+----------+----------+\n",
      "|city1                                |city2                                |passengers|fare  |nsmiles|large_ms|lf_ms |fare_lg|fare_low|Label_thật|Dự_đoán   |\n",
      "+-------------------------------------+-------------------------------------+----------+------+-------+--------+------+-------+--------+----------+----------+\n",
      "|Chicago, IL                          |Tulsa, OK                            |219       |159.12|585    |0.68    |0.28  |158.78 |157.54  |Cao       |Cao       |\n",
      "|Miami, FL (Metropolitan Area)        |Pittsburgh, PA                       |218       |168.14|1013   |0.77    |0.04  |171.81 |109.38  |Cao       |Cao       |\n",
      "|Indianapolis, IN                     |New York City, NY (Metropolitan Area)|447       |240.15|700    |0.77    |0.11  |250.35 |200.6   |Cao       |Cao       |\n",
      "|New York City, NY (Metropolitan Area)|Phoenix, AZ                          |1         |119.2 |2189   |1.0     |1.0   |119.2  |119.2   |Thấp      |Thấp      |\n",
      "|Hartford, CT                         |Miami, FL (Metropolitan Area)        |149       |149.31|1194   |0.56    |0.56  |146.85 |146.85  |Cao       |Cao       |\n",
      "|Nashville, TN                        |Washington, DC (Metropolitan Area)   |641       |216.03|587    |0.9327  |0.9327|214.57 |214.57  |Trung bình|Trung bình|\n",
      "|Dallas/Fort Worth, TX                |Miami, FL (Metropolitan Area)        |541       |220.13|1121   |0.84    |0.03  |227.52 |143.8   |Cao       |Cao       |\n",
      "|Boston, MA (Metropolitan Area)       |Charleston, SC                       |21        |209.21|836    |0.5213  |0.5213|194.64 |194.64  |Cao       |Cao       |\n",
      "|Boston, MA (Metropolitan Area)       |Richmond, VA                         |428       |137.86|487    |0.6393  |0.6393|134.02 |134.02  |Cao       |Cao       |\n",
      "|New York City, NY (Metropolitan Area)|Reno, NV                             |186       |226.06|2443   |0.7715  |0.7715|192.7  |192.7   |Thấp      |Thấp      |\n",
      "+-------------------------------------+-------------------------------------+----------+------+-------+--------+------+-------+--------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, col, rand\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Ánh xạ nhãn số sang tên (theo thứ tự StringIndexer đã huấn luyện)\n",
    "label_mapping = {0.0: \"Cao\", 1.0: \"Trung bình\", 2.0: \"Thấp\"}\n",
    "map_label_udf = udf(lambda x: label_mapping.get(x, \"Không rõ\"), StringType())\n",
    "\n",
    "# Lấy 10 mẫu ngẫu nhiên từ tập test\n",
    "sample_test = test_data.orderBy(rand()).limit(10)\n",
    "\n",
    "# Xác định mô hình tốt nhất\n",
    "if best_model[\"name\"] == \"Random Forest\":\n",
    "    best_model_object = best_rf_model\n",
    "elif best_model[\"name\"] == \"Logistic Regression\":\n",
    "    best_model_object = best_lr_model\n",
    "else:\n",
    "    raise ValueError(\"Không xác định được mô hình tốt nhất!\")\n",
    "\n",
    "# Dự đoán\n",
    "sample_predictions = best_model_object.transform(sample_test)\n",
    "\n",
    "# Thêm nhãn thật và dự đoán dạng chữ\n",
    "sample_with_labels = (\n",
    "    sample_predictions\n",
    "    .withColumn(\"Label_thật\", map_label_udf(col(\"label\")))\n",
    "    .withColumn(\"Dự_đoán\", map_label_udf(col(\"prediction\")))\n",
    ")\n",
    "\n",
    "# Hiển thị các cột chính\n",
    "columns_to_show = [\n",
    "    \"city1\", \"city2\", \"passengers\", \"fare\", \"nsmiles\",\n",
    "    \"large_ms\", \"lf_ms\", \"fare_lg\", \"fare_low\",\n",
    "    \"Label_thật\", \"Dự_đoán\"\n",
    "]\n",
    "\n",
    "print(f\"\\n Dự đoán 10 mẫu ngẫu nhiên bằng mô hình tốt nhất: {best_model['name']}\")\n",
    "sample_with_labels.select(columns_to_show).show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
